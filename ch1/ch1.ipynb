{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始1H间隔数据\n",
      "                           value\n",
      "2022-01-01 00:00:00+00:00     40\n",
      "2022-01-01 01:00:00+00:00     28\n",
      "2022-01-01 02:00:00+00:00     63\n",
      "2022-01-01 03:00:00+00:00     87\n",
      "2022-01-01 04:00:00+00:00     91\n",
      "2022-01-01 05:00:00+00:00     39\n",
      "2022-01-01 06:00:00+00:00      1\n",
      "2022-01-01 07:00:00+00:00     97\n",
      "\n",
      "降采样3H间隔数据\n",
      "                           value\n",
      "2022-01-01 00:00:00+00:00    131\n",
      "2022-01-01 03:00:00+00:00    217\n",
      "2022-01-01 06:00:00+00:00     98\n"
     ]
    }
   ],
   "source": [
    "# ch1/ch1.ipynb\n",
    "# 第三方库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 高频数据构造\n",
    "date = pd.date_range(\n",
    "    '2022-01-01 00:00:00',  # 开始时间\n",
    "    '2022-01-01 08:00:00',  # 结束时间\n",
    "    freq='1H',  # 间隔时间\n",
    "    closed='left',  # 左闭右开\n",
    "    tz='UTC'  # 时区\n",
    ")\n",
    "value = np.random.randint(1, 100, len(date))\n",
    "data = pd.DataFrame({'value': value}, index=date)\n",
    "print('原始1H间隔数据')\n",
    "print(data)\n",
    "\n",
    "# 降采样到3H间隔\n",
    "data = data.resample('3H').sum()\n",
    "print()\n",
    "print('降采样3H间隔数据')\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 缺失值补全"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有缺失数据集\n",
      "                       date  value\n",
      "0 2022-01-01 00:00:00+00:00   96.0\n",
      "1 2022-01-01 01:00:00+00:00   53.0\n",
      "2 2022-01-01 02:00:00+00:00   11.0\n",
      "3                       NaT    NaN\n",
      "4 2022-01-01 04:00:00+00:00   46.0\n",
      "5 2022-01-01 05:00:00+00:00   23.0\n",
      "6                       NaT    NaN\n",
      "7 2022-01-01 07:00:00+00:00   35.0\n",
      "\n",
      "缺失值补全数据集\n",
      "                       date  value\n",
      "0 2022-01-01 00:00:00+00:00   96.0\n",
      "1 2022-01-01 01:00:00+00:00   53.0\n",
      "2 2022-01-01 02:00:00+00:00   11.0\n",
      "3 2022-01-01 03:00:00+00:00   28.5\n",
      "4 2022-01-01 04:00:00+00:00   46.0\n",
      "5 2022-01-01 05:00:00+00:00   23.0\n",
      "6 2022-01-01 06:00:00+00:00   29.0\n",
      "7 2022-01-01 07:00:00+00:00   35.0\n"
     ]
    }
   ],
   "source": [
    "# ch1/ch1.ipynb\n",
    "# 第三方库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 完整数据构造\n",
    "date = pd.date_range(\n",
    "    '2022-01-01 00:00:00',  # 开始时间\n",
    "    '2022-01-01 08:00:00',  # 结束时间\n",
    "    freq='1H',  # 间隔时间\n",
    "    closed='left',  # 左闭右开\n",
    "    tz='UTC'  # 时区\n",
    ")\n",
    "value = np.random.randint(1, 100, len(date))\n",
    "data = pd.DataFrame({\n",
    "    'date': date,\n",
    "    'value': value\n",
    "})\n",
    "\n",
    "# 随机设置缺失值\n",
    "data.iloc[[3, 6], :] = None\n",
    "print('有缺失数据集')\n",
    "print(data)\n",
    "\n",
    "# 缺失值补全\n",
    "data.set_index('date', inplace=True)  # 设置时间为索引\n",
    "data = data.resample('1H').mean()  # 补全缺失时间\n",
    "data.interpolate(method='time', inplace=True)  # 插值\n",
    "data.reset_index(inplace=True)  # 恢复默认索引\n",
    "print()\n",
    "print('缺失值补全数据集')\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 归一化和标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape=(500, 10), train_y.shape=(500, 1)\n",
      "test_x.shape=(100, 10), test_y.shape=(100, 1)\n",
      "train_x.min()=0.0005, train_x.max()=99.8647\n",
      "train_y.min()=0.1415, train_y.max()=99.8912\n",
      "test_x.min()=0.0701, test_x.max()=99.6524\n",
      "test_y.min()=1.8336, test_y.max()=96.8094\n",
      "\n",
      "train_x_n.shape=(500, 10), train_y_n.shape=(500, 1)\n",
      "test_x_n.shape=(100, 10), test_y_n.shape=(100, 1)\n",
      "train_x_n.min()=0.0000, train_x_n.max()=1.0000\n",
      "train_y_n.min()=0.0000, train_y_n.max()=1.0000\n",
      "test_x_n.min()=0.0005, test_x_n.max()=1.0007\n",
      "test_y_n.min()=0.0170, test_y_n.max()=0.9691\n",
      "\n",
      "train_x_n.shape=(500, 10), train_y_n.shape=(500, 1)\n",
      "test_x_n.shape=(100, 10), test_y_n.shape=(100, 1)\n",
      "train_x_n.min()=-1.8114, train_x_n.max()=1.7516\n",
      "train_y_n.min()=-1.7133, train_y_n.max()=1.7309\n",
      "test_x_n.min()=-1.7773, test_x_n.max()=1.7413\n",
      "test_y_n.min()=-1.6549, test_y_n.max()=1.6244\n"
     ]
    }
   ],
   "source": [
    "# ch1/ch1.ipynb\n",
    "# 第三方库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# 随机初始化生成数据\n",
    "train_x = np.random.random((500, 10))*100  # [num_train, H]\n",
    "train_y = np.random.random((500, 1))*100  # [num_train, 1]\n",
    "test_x = np.random.random((100, 10))*100  # [num_test, H]\n",
    "test_y = np.random.random((100, 1))*100  # [num_test, 1]\n",
    "\n",
    "# 查看未归一化/标准化时的数据维度和范围\n",
    "print(f'{train_x.shape=}, {train_y.shape=}')\n",
    "print(f'{test_x.shape=}, {test_y.shape=}')\n",
    "print(f'{train_x.min()=:.4f}, {train_x.max()=:.4f}')\n",
    "print(f'{train_y.min()=:.4f}, {train_y.max()=:.4f}')\n",
    "print(f'{test_x.min()=:.4f}, {test_x.max()=:.4f}')\n",
    "print(f'{test_y.min()=:.4f}, {test_y.max()=:.4f}')\n",
    "\n",
    "# 初始化 MinMaxScaler\n",
    "x_scalar = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scalar = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# 训练集和测试集归一化\n",
    "train_x_n = x_scalar.fit_transform(train_x)  # [num_train, H]\n",
    "test_x_n = x_scalar.transform(test_x)  # [num_test, H]\n",
    "train_y_n = y_scalar.fit_transform(train_y)  # [num_train, 1]\n",
    "test_y_n = y_scalar.transform(test_y)  # [num_test, 1]\n",
    "\n",
    "# 查看归一化后的数据维度和范围\n",
    "print(f'\\n{train_x_n.shape=}, {train_y_n.shape=}')\n",
    "print(f'{test_x_n.shape=}, {test_y_n.shape=}')\n",
    "print(f'{train_x_n.min()=:.4f}, {train_x_n.max()=:.4f}')\n",
    "print(f'{train_y_n.min()=:.4f}, {train_y_n.max()=:.4f}')\n",
    "print(f'{test_x_n.min()=:.4f}, {test_x_n.max()=:.4f}')\n",
    "print(f'{test_y_n.min()=:.4f}, {test_y_n.max()=:.4f}')\n",
    "\n",
    "# 初始化 StandardScaler\n",
    "x_scalar = StandardScaler()\n",
    "y_scalar = StandardScaler()\n",
    "\n",
    "# 训练集和测试集标准化\n",
    "train_x_n = x_scalar.fit_transform(train_x)  # [num_train, H]\n",
    "test_x_n = x_scalar.transform(test_x)  # [num_test, H]\n",
    "train_y_n = y_scalar.fit_transform(train_y)  # [num_train, 1]\n",
    "test_y_n = y_scalar.transform(test_y)  # [num_test, 1]\n",
    "\n",
    "# 查看标准化后的数据维度和范围\n",
    "print(f'\\n{train_x_n.shape=}, {train_y_n.shape=}')\n",
    "print(f'{test_x_n.shape=}, {test_y_n.shape=}')\n",
    "print(f'{train_x_n.min()=:.4f}, {train_x_n.max()=:.4f}')\n",
    "print(f'{train_y_n.min()=:.4f}, {train_y_n.max()=:.4f}')\n",
    "print(f'{test_x_n.min()=:.4f}, {test_x_n.max()=:.4f}')\n",
    "print(f'{test_y_n.min()=:.4f}, {test_y_n.max()=:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 时间序列转监督学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape=(5, 5), y.shape=(5,)\n",
      "X=array([[1., 2., 3., 4., 5.],\n",
      "       [2., 3., 4., 5., 6.],\n",
      "       [3., 4., 5., 6., 7.],\n",
      "       [4., 5., 6., 7., 8.],\n",
      "       [5., 6., 7., 8., 9.]]), \n",
      "y=array([ 6.,  7.,  8.,  9., 10.])\n"
     ]
    }
   ],
   "source": [
    "# ch1/ch1.ipynb\n",
    "# 第三方库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def series_to_supervised(series, H):\n",
    "    \"\"\"时间序列数据转监督学习数据\n",
    "\n",
    "    参数:\n",
    "        series (list or 1d numpy array): 时间序列数据\n",
    "        H (int): 输入历史值数量\n",
    "\n",
    "    返回值:\n",
    "        numpy array: 监督学习数据集, 特征和标签\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(series)-H):\n",
    "        seq_x = series[i:i+H]  # 从位置i开始截取长度为H的输入\n",
    "        seq_y = series[i+H]  # 取位置i+H的单个数值为输出\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)  # 转换List变量为Numpy Array变量\n",
    "\n",
    "\n",
    "# 时间序列数据构造\n",
    "data = np.linspace(1, 10, 10)\n",
    "\n",
    "# 输入输出划分\n",
    "X, y = series_to_supervised(data, 5)\n",
    "print(f'{X.shape=}, {y.shape=}')\n",
    "print(f'{X=}, \\n{y=}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
